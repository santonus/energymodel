# -*- coding: utf-8 -*-
"""multivariate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tB_uJB-0pA11EdnHN_FJ7_clfToW6JhU
"""

import pandas as pd
from sklearn.datasets import load_iris
from factor_analyzer import FactorAnalyzer
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/gdrive')

df=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Power Model Inputs - Kepler_data_original.csv')
print(df.columns)

df1=df.drop(['Sr No.','Benchmark','Kernel Name'],axis=1)

df1=df1[df1['avg_shar_lat']!='#DIV/0!']
df1=df1[df1['avg_shar_lat']!=' ']
df1=df1[df1['avg_glob_lat']!='#DIV/0!']
df1=df1[df1['avg_misc_lat']!='#DIV/0!']
df1=df1[df1['avg_comp_lat']!='#DIV/0!']

df1=df1[df1['avg_shar_lat']!='#REF!']

df1['avg_shar_lat']=df1['avg_shar_lat'].astype('float64')
df1['avg_glob_lat']=df1['avg_glob_lat'].astype('float64')
df1['avg_comp_lat']=df1['avg_comp_lat'].astype('float64')
df1['avg_misc_lat']=df1['avg_misc_lat'].astype('float64')
df1

df1=df1.drop(['wtotal','Global_Throughput','sh_throughput','total_inst','comp_lat_sim','glob_lat_sim','misc_lat_sim','shar_lat_sim','glob_inst_sim','shar_inst_sim','misc_inst_sim','comp_inst_sim','glb_penalty','waves','grid_size','Total Threads','sm_active','shar_inst_kernel','sh_penalty','avg_misc_lat','n_warps'],axis=1)
df1=df1.dropna(axis=0,how='any')
df1

y_train=df1['Power']
y_train=np.array(y_train).astype('float32')
y_train.shape
y_train

x_train=df1.iloc[:,0:15]
x_train=np.array(x_train).astype('float32')
x_train

df1.columns

#data scaling
from sklearn import preprocessing
min_max_scaler = preprocessing.StandardScaler()
X_scale = min_max_scaler.fit_transform(x_train)
print(X_scale.shape)


#splitting the data for training and validation test
from sklearn.utils import shuffle
X_scale,y_train = shuffle(X_scale, y_train, random_state=0)
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y_train, test_size=0.2)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)


# importing module
from sklearn.linear_model import LinearRegression
# creating an object of LinearRegression class
LR = LinearRegression()
# fitting the training data
LR.fit(X_train,Y_train)

Y_prediction =  LR.predict(X_test)
Y_prediction

# importing r2_score module
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
# predicting the accuracy score
score=r2_score(Y_test,Y_prediction)
print('r2 score is' ,score)
print('mean_sqrd_error is=',mean_squared_error(Y_test,Y_prediction))
print('root_mean_squared error of is=',np.sqrt(mean_squared_error(Y_test,Y_prediction)))

plt.plot(x_train[:,14], y_train)
plt.xlabel('cache_penalty')
# naming the y axis
plt.ylabel('power (Watts)')
plt.show()

import seaborn as sns
dist=sns.displot(x_train[:,12],kde=True,rug=True )
dist.set(xlabel='inst_issue_cycle')

print(x_train[:,0])