# -*- coding: utf-8 -*-
"""Decision_tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pNjFkMbffdRFwr_ea-_tpbuFNMV8o4lk
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/gdrive')

3df=pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/KeplerHDBSCAN.csv')
print(df.columns)

#df=pd.read_csv('/content/Power Model Inputs - Kepler_data_original.csv')
#print(df.columns)

df1=df.drop(['Sr No.','Benchmark','Kernel Name'],axis=1)

df1=df1[df1['avg_shar_lat']!='#DIV/0!']
df1=df1[df1['avg_shar_lat']!=' ']
df1=df1[df1['avg_glob_lat']!='#DIV/0!']
df1=df1[df1['avg_misc_lat']!='#DIV/0!']
df1=df1[df1['avg_comp_lat']!='#DIV/0!']

df1=df1[df1['avg_shar_lat']!='#REF!']

df1['avg_shar_lat']=df1['avg_shar_lat'].astype('float64')
df1['avg_glob_lat']=df1['avg_glob_lat'].astype('float64')
df1['avg_comp_lat']=df1['avg_comp_lat'].astype('float64')
df1['avg_misc_lat']=df1['avg_misc_lat'].astype('float64')
df1

df1=df1.drop(['wtotal','Global_Throughput','sh_throughput','total_inst','comp_lat_sim','glob_lat_sim','misc_lat_sim','shar_lat_sim','glob_inst_sim','shar_inst_sim','misc_inst_sim','comp_inst_sim','glb_penalty','waves','grid_size','Total Threads','sm_active','shar_inst_kernel','sh_penalty','avg_misc_lat','n_warps'],axis=1)
df1=df1.dropna(axis=0,how='any')
df1
df2=df1.drop(['Power'],axis=1)
y_train=df1['Power']
y_train=np.array(y_train).astype('float32')
y_train.shape
x_train=df1.iloc[:,0:15]
x_train=np.array(x_train).astype('float32')
x_train

from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
X_scale = min_max_scaler.fit_transform(x_train)
print(X_scale.shape)

#splitting the data for training and validation test
from sklearn.utils import shuffle
X_scale,y_train = shuffle(X_scale, y_train, random_state=0)
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X_scale, y_train, test_size=0.2)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

from sklearn.tree import DecisionTreeRegressor
regr = DecisionTreeRegressor(random_state = 0)

parameters={"splitter":["best","random"],
            "max_depth" : [1,3,5,7,9,11,12],
           "min_samples_leaf":[1,2,3,4,5,6,7,8,9,10],
           "min_weight_fraction_leaf":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],
           "max_features":["auto","log2","sqrt",None],
           "max_leaf_nodes":[None,10,20,30,40,50,60,70,80,90] }

from sklearn.model_selection import GridSearchCV
CV_rfc = GridSearchCV(estimator=regr, param_grid=parameters, cv= 5)
CV_rfc.fit(X_scale, y_train)

CV_rfc.best_params_

#rfc1=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=3, max_features='auto', max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.1, random_state=0, splitter='best')

rfc1=DecisionTreeRegressor()

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
scores = cross_val_score(rfc1, X_scale, y_train, cv=5)
print(scores)

print(scores.mean())

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
scores = cross_val_score(rfc1, X_scale, y_train, cv=5,scoring='neg_root_mean_squared_error')
print(scores)

print(scores.mean())

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
scores = cross_val_score(rfc1, X_scale, y_train, cv=5,scoring='neg_mean_absolute_error')
print(scores)

print(scores.mean())

rfc1.fit(X_train,Y_train)
rfc1.score(X_test,Y_test)

pred=rfc1.predict(X_test)

rfc1.score(X_train,Y_train)

from sklearn.metrics import mean_squared_error
print('RMSE:')
print(np.sqrt(mean_squared_error(Y_test,pred)))

from sklearn.metrics import mean_absolute_error
print(mean_absolute_error(Y_test,pred))

import matplotlib.pyplot as plt
plt.plot(Y_test,pred,"co")

import pickle
pkl_filename = "extraTrees_model.pkl"
with open(pkl_filename, 'wb') as file:
    pickle.dump(rfc1, file)